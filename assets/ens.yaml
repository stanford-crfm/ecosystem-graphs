---
- type: dataset
  name: HowTo100M
  organization: École Normale Supérieure, Inria
  description: HowTo100M is a large-scale dataset of narrated videos with an emphasis
    on instructional videos where content creators teach complex tasks with an explicit
    intention of explaining the visual content on screen. HowTo100M features a total
    of 136M video clips with captions sourced from 1.2M Youtube videos (15 years
    of video) and 23k activities from domains such as cooking, hand crafting, personal
    care, gardening or fitness.
  created_date:
    explanation: The date the [[paper]](https://arxiv.org/abs/1906.03327) was submitted.
    value: 2019-06-07
  url: https://arxiv.org/pdf/1906.03327.pdf
  datasheet: https://arxiv.org/pdf/1906.03327.pdf
  modality: {}
  size: 136M video clips
  sample: []
  analysis:
    explanation: See [[Experiments]](https://arxiv.org/pdf/1906.03327v2.pdf#section.5)
    value: Authors use the dataset to learn a joint text-video embedding by leveraging
      more than 130M video clip-caption pairs. They then evaluate the learned embeddings
      on the tasks of localizing steps in instructional videos of CrossTask and
      textbased video retrieval on YouCook2, MSR-VTT and LSMDC datasets. They show
      that their learned embedding can perform better compared to models trained
      on existing carefully annotated but smaller video description datasets.
  dependencies: [YouTube]
  included:
    explanation: See [[Data collection]](https://arxiv.org/pdf/1906.03327v2.pdf#subsection.3.1)
    value: The dataset features 1.22 million videos from YouTube with a primary
      focus on videos containing "visual tasks", that involve some interaction with
      the physical world (e.g. Making peanut butter, Pruning a tree) as compared
      to others that are more abstract (e.g. Ending a toxic relationship, Choosing
      a gift). To obtain predominantly visual tasks, the authors limit them to one
      of 12 categories (Food and Entertaining, Home and Garden, Hobbies and Crafts,
      Cars & Other Vehicles, Pets and Animals, Holidays and Traditions, Personal
      Care and Style, Sports and Fitness, Health, Education and Communications,
      Arts and Entertainment, Computers and Electronics). They also restrict to
      the top 200 YouTube search results, as the latter ones may not be related
      to the query task.
  excluded:
    explanation: See [[Data collection]](https://arxiv.org/pdf/1906.03327v2.pdf#subsection.3.1)
    value: Categories such as Relationships and Finance and Business, that may be
      more abstract, are excluded. Videos with less than 100 views are removed.
      Authors also ignore videos that have less than 100 words. Videos longer than
      2,000 seconds are removed. As some videos may appear in several tasks, the
      videos are deduplicated based on YouTube IDs.
  quality_control: ''
  access:
    explanation: Dataset, evaluation code and models are publicly available at the
      [[HowTo100M dataset webpage]](https://www.di.ens.fr/willow/research/howto100m/).
    value: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses:
    explanation: See [[HowTo100M dataset webpage]](https://www.di.ens.fr/willow/research/howto100m/)
    value: "No uses are explicitly prohibited by the authors. They note the following\
      \ limitations of the dataset: \"We note that the distribution of identities\
      \ and activities in the HowTo100M dataset may not be representative of the\
      \ global human population and the diversity in society. Please be careful\
      \ of unintended societal, gender, racial and other biases when training or\
      \ deploying models trained on this data.\"\n"
  monitoring: ''
  feedback: ''
