---
- type: model
  name: Prithvi
  organization: IBM
  description: Prithvi is a first-of-its-kind temporal Vision transformer pre-trained
    by the IBM and NASA team on contiguous US Harmonised Landsat Sentinel 2 (HLS)
    data. The model adopts a self-supervised encoder developed with a ViT architecture
    and Masked AutoEncoder (MAE) learning strategy, with an MSE loss function.
  created_date:
    explanation: The date the model was announced in the [[Adept blog post]](https://www.adept.ai/blog/act-1).
    value: 2023-08-03
  url: https://github.com/NASA-IMPACT/hls-foundation-os
  model_card: https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M
  modality:
    explanation: video; text
    value: text, video; text, video
  analysis: ''
  size: 100M parameters (dense)
  dependencies: [NASA HLS data]
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M/discussions
- type: application
  name: Watsonx.ai
  organization: IBM
  description: Watsonx.ai is part of the IBM watsonx platform that brings together
    new generative AI capabilities, powered by foundation models and traditional
    machine learning into a powerful studio spanning the AI lifecycle.
  created_date: 2023-09-07
  url: https://www.ibm.com/products/watsonx-ai
  dependencies: [Granite]
  adaptation: ''
  output_space: deployed AI models
  quality_control: ''
  access: limited
  license:
    explanation: License information can be found at https://www.ibm.com/docs/en/watsonxdata/1.0.x?topic=planning-licenses-entitlements
    value: custom
  terms_of_service: https://www.ibm.com/docs/en/watsonx-as-a-service?topic=models-terms-use
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
  monthly_active_users: ''
  user_distribution: ''
  failures: ''
- type: model
  name: Granite
  organization: IBM
  description: Granite is a set of multi-size foundation models that apply generative
    AI to both language and code.
  created_date: 2023-09-28
  url: https://www.ibm.com/blog/building-ai-for-business-ibms-granite-foundation-models/
  model_card: none
  modality: text; code, text
  analysis: unknown
  size: 13B parameters (dense)
  dependencies: []
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: Training data passed through IBM HAP detector, language model
    designed to remove harmful content. Data also deduplicated and filtered for
    document quality.
  access: limited
  license: ''
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: ColPali
  organization: illuin.tech
  description: ColPali is a model based on Vision Language Models (VLMs) for efficiently indexing documents from their visual features. It is an extension of the PaliGemma-3B model that generates ColBERT- style multi-vector representations of text and images. The model is designed to compute interactions between text tokens and image patches, providing a significant improvement in performance.
  created_date: 2024-07-01 (Assumed based on the arXiv paper submission date)
  url: https://huggingface.co/vidore/colpali
  model_card: https://huggingface.co/vidore/colpali
  modality: image + text document; text
  analysis: Unknown
  size: Specific number of parameters unknown. However, since it's built on PaliGemma-3B, its parameters likely reside in the range of billions ('B').
  dependencies: [SigLIP, PaliGemma-3B, BiSigLIP, BiPali, Claude-3 Sonnet]
  training_emissions: Unknown
  training_time: One epoch on the train set
  training_hardware: 8 GPU setup with data parallelism
  quality_control: The model was trained using a validation set for tuning hyperparameters. It was explicitly verified that no PDF document used in ViDoRe is present in the train set to prevent evaluation contamination.
  access: Open (Released in the illuin.tech repository)
  license: gemma (for PaliGemma); MIT (for the model-specific adapters)
  intended_uses: ColPali is primarily designed for efficient document retrieval, taking visual features into account.
  prohibited_uses: The model should not be used for multi-vector retrieval purposes that lack native multi-vector support, unless additional engineering effort is applied. Also, the model mainly works with English and high-resource languages and PDF-type documents; it's not intended for work with less represented languages or other document types without modification.
  monitoring: Unknown
  feedback: For downstream problems with this model, report to Manuel Faysse (manuel.faysse@illuin.tech), Hugues Sibille (hugues.sibille@illuin.tech), or Tony Wu (tony.wu@illuin.tech).
