---
- type: model
  name: SALMONN
  organization: ByteDance, Tsinghua University
  description: SALMONN is a large language model (LLM) enabling speech, audio event,
    and music inputs.
  created_date: 2023-10-20
  url: https://github.com/bytedance/SALMONN
  model_card: https://huggingface.co/MSIIP/SALMONN
  modality: audio, text; text
  analysis: Evaluated on benchmarks pertaining to speech, music, and other audio
    recognition.
  size: unknown
  dependencies: [Whisper, BEATs, Vicuna]
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: none
  feedback: https://huggingface.co/MSIIP/SALMONN/discussions
- type: model
  name: SDXL-Lightning
  organization: ByteDance
  description: SDXL-Lightning is a lightning-fast text-to-image generation model.
    It can generate high-quality 1024px images in a few steps. The models are distilled
    from stabilityai/stable-diffusion-xl-base-1.0. This repository contains checkpoints
    for 1-step, 2-step, 4-step, and 8-step distilled models.
  created_date: 2024-02-21
  url: https://arxiv.org/pdf/2402.13929.pdf
  model_card: https://huggingface.co/ByteDance/SDXL-Lightning
  modality: text; image
  analysis: Evaluated via qualitative comparison relative to other SoTA image generation
    models.
  size: unknown
  dependencies: [Stable Diffusion XL]
  training_emissions: unknown
  training_time: unknown
  training_hardware: 64 A100 80G GPUs
  quality_control: unknown
  access: open
  license: OpenRail++
  intended_uses: The model can be used for fast, high-quality text-to-image generation.
    It supports 1-step, 2-step, 4-step, and 8-step distilled models which provide
    varying generation quality.
  prohibited_uses: unknown
  monitoring: unknown
  feedback: https://huggingface.co/ByteDance/SDXL-Lightning/discussions
- type: model
  name: LLaVA-Critic
  organization: ByteDance, University of Maryland, College Park
  description: LLaVA-Critic is an open-source large multimodal model developed to evaluate and assess performance across various multimodal tasks. It functions as a generalist evaluator, designed to provide reliable evaluation scores and enhance preference learning capabilities. The model was trained using a high-quality critic instruction-following dataset, which helps it perform tasks like LMM-as-a-Judge and preference learning with efficacy comparable to or surpassing existing GPT models.
  created_date: 2024-10-06
  url: https://arxiv.org/pdf/2410.02712
  model_card: unknown
  modality: text; image
  analysis: The model was evaluated in tasks where it provided evaluation scores for multimodal models and in preference learning, where it generated reward signals. It was shown to have high correlation with commercial GPT models, making it a cost-effective alternative in resource-constrained settings.
  size: unknown
  dependencies: []
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: The model uses a high-quality dataset for instruction-following and evaluation to ensure transparent and consistent performance assessments.
  access: open
  license: unknown
  intended_uses: The model can be used for scalable performance evaluations, preference learning, reinforcement learning signals, and guiding inference-time search in multimodal models.
  prohibited_uses: unknown
  monitoring: unknown
  feedback: unknown

