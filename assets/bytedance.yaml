---
- type: model
  name: SALMONN
  organization: ByteDance, Tsinghua University
  description: SALMONN is a large language model (LLM) enabling speech, audio event,
    and music inputs.
  created_date: 2023-10-20
  url: https://github.com/bytedance/SALMONN
  model_card: https://huggingface.co/MSIIP/SALMONN
  modality: audio, text; text
  analysis: Evaluated on benchmarks pertaining to speech, music, and other audio
    recognition.
  size: unknown
  dependencies: [Whisper, BEATs, Vicuna]
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: none
  feedback: https://huggingface.co/MSIIP/SALMONN/discussions
- type: model
  name: SDXL-Lightning
  organization: ByteDance
  description: SDXL-Lightning is a lightning-fast text-to-image generation model.
    It can generate high-quality 1024px images in a few steps. The models are distilled
    from stabilityai/stable-diffusion-xl-base-1.0. This repository contains checkpoints
    for 1-step, 2-step, 4-step, and 8-step distilled models.
  created_date: 2024-02-21
  url: https://arxiv.org/pdf/2402.13929.pdf
  model_card: https://huggingface.co/ByteDance/SDXL-Lightning
  modality: text; image
  analysis: Evaluated via qualitative comparison relative to other SoTA image generation
    models.
  size: unknown
  dependencies: [Stable Diffusion XL]
  training_emissions: unknown
  training_time: unknown
  training_hardware: 64 A100 80G GPUs
  quality_control: unknown
  access: open
  license: OpenRail++
  intended_uses: The model can be used for fast, high-quality text-to-image generation.
    It supports 1-step, 2-step, 4-step, and 8-step distilled models which provide
    varying generation quality.
  prohibited_uses: unknown
  monitoring: unknown
  feedback: https://huggingface.co/ByteDance/SDXL-Lightning/discussions
- type: model
  name: LLaVA-Critic
  organization: ByteDance, University of Maryland, College Park
  description: LLaVA-Critic is the first open-source large multimodal model (LMM) designed to act as a generalist evaluator, assessing performance across a diverse range of multimodal tasks. It is trained using a high-quality critic instruction-following dataset that incorporates varied evaluation criteria and scenarios. LLaVA-Critic is effective as a judge in evaluation benchmarks and in generating reward signals for preference learning, enhancing model alignment capabilities.
  created_date: 2024-10-06
  url: https://arxiv.org/pdf/2410.02712
  model_card: unknown
  modality: text, image; evaluation scores
  analysis: Evaluated against GPT models on multiple benchmarks, showing reliable evaluation scores and a high correlation with commercial GPT models, serving as a cost-effective alternative for model evaluation.
  size: unknown
  dependencies: [GPT-4V, GPT-4o, LLaVA-Instruction-150k, SVIT, ComVint, LLaVAR, LRV-Instruction, M3IT, LLaVA-Med, PCA-EVAL, VLFeedback]
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: Ensures transparency and consistency by providing reasoning behind evaluations and is trained with a high-quality dataset.
  access: open
  license: unknown
  intended_uses: Evaluating multimodal model performance, generating reward signals in preference learning, and providing scalable alternatives for model evaluation.
  prohibited_uses: unknown
  monitoring: unknown
  feedback: unknown

