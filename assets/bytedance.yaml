---
- type: model
  name: SALMONN
  organization: ByteDance, Tsinghua University
  description: SALMONN is a large language model (LLM) enabling speech, audio event,
    and music inputs.
  created_date: 2023-10-20
  url: https://github.com/bytedance/SALMONN
  model_card: https://huggingface.co/MSIIP/SALMONN
  modality: audio, text; text
  analysis: Evaluated on benchmarks pertaining to speech, music, and other audio
    recognition.
  size: unknown
  dependencies: [Whisper, BEATs, Vicuna]
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: ''
  access: open
  license: Apache 2.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: none
  feedback: https://huggingface.co/MSIIP/SALMONN/discussions
- type: model
  name: SDXL-Lightning
  organization: ByteDance
  description: SDXL-Lightning is a lightning-fast text-to-image generation model.
    It can generate high-quality 1024px images in a few steps. The models are distilled
    from stabilityai/stable-diffusion-xl-base-1.0. This repository contains checkpoints
    for 1-step, 2-step, 4-step, and 8-step distilled models.
  created_date: 2024-02-21
  url: https://arxiv.org/pdf/2402.13929.pdf
  model_card: https://huggingface.co/ByteDance/SDXL-Lightning
  modality: text; image
  analysis: Evaluated via qualitative comparison relative to other SoTA image generation
    models.
  size: unknown
  dependencies: [Stable Diffusion XL]
  training_emissions: unknown
  training_time: unknown
  training_hardware: 64 A100 80G GPUs
  quality_control: unknown
  access: open
  license: OpenRail++
  intended_uses: The model can be used for fast, high-quality text-to-image generation.
    It supports 1-step, 2-step, 4-step, and 8-step distilled models which provide
    varying generation quality.
  prohibited_uses: unknown
  monitoring: unknown
  feedback: https://huggingface.co/ByteDance/SDXL-Lightning/discussions
- type: model
  name: LLaVA-Critic
  organization: ByteDance, University of Maryland, College Park
  description: LLaVA-Critic is the first open-source large multimodal model designed as a generalist evaluator to assess the performance across a wide range of multimodal tasks. It's trained on a high-quality critic instruction-following dataset incorporating diverse evaluation criteria. It's effective in tasks like LMM-as-a-Judge and Preference Learning, providing reliable evaluation scores and generating reward signals for preference learning.
  created_date: 2024-10-06
  url: https://arxiv.org/pdf/2410.02712
  model_card: unknown
  modality: multimodal; scores and feedback
  analysis: The model's effectiveness was demonstrated in tasks like performing evaluations on par with or surpassing GPT models on multiple benchmarks, and generating reward signals for preference learning.
  size: unknown
  dependencies: [GPT-4V, LLaVA-RLHF]
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: Evaluation through comparing it with commercial models like GPT-4V on multiple benchmarks.
  access: open
  license: unknown
  intended_uses: Evaluation of multimodal models, preference learning by generating effective reward signals.
  prohibited_uses: unknown
  monitoring: unknown
  feedback: unknown

