---
- type: model
  name: Yi
  organization: 01 AI
  description: The Yi series models are large language models trained from scratch
    by developers at 01 AI.
  created_date: 2023-11-02
  url: https://github.com/01-ai/Yi
  model_card: https://huggingface.co/01-ai/Yi-34B
  modality: text; text
  analysis: Evaluated on standard language benchmarks, common sense reasoning, and
    reading comprehension in comparison to SoTA LLMs.
  size: 34B parameters (dense)
  dependencies: []
  training_emissions: unknown
  training_time: unknown
  training_hardware: unknown
  quality_control: Model underwent supervised fine-tuning, leading to a greater
    diversity of responses.
  access: open
  license:
    explanation: Model license can be found at https://huggingface.co/01-ai/Yi-34B/blob/main/LICENSE.
      Code license is under Apache 2.0
    value: custom
  intended_uses: ''
  prohibited_uses: none
  monitoring: unknown
  feedback: https://huggingface.co/01-ai/Yi-34B/discussions
- type: model
  name: Yi-VL
  organization: 01 AI
  description: The Yi Vision Language (Yi-VL) model is the open-source, multimodal
    version of the Yi Large Language Model (LLM) series, enabling content comprehension,
    recognition, and multi-round conversations about images.
  created_date: 2024-01-23
  url: https://github.com/01-ai/Yi
  model_card: https://huggingface.co/01-ai/Yi-VL-34B
  modality: text; text
  analysis: Yi-VL outperforms all existing open-source models in MMMU and CMMMU,
    two advanced benchmarks that include massive multi-discipline multimodal questions
    (based on data available up to January 2024).
  size: 34B parameters (dense)
  dependencies: []
  training_emissions: unknown
  training_time: 10 days
  training_hardware: 128 NVIDIA A800 (80G) GPUs
  quality_control: unknown
  access: open
  license:
    explanation: Model license can be found at https://huggingface.co/01-ai/Yi-VL-34B/blob/main/LICENSE.
      Code license is under Apache 2.0
    value: custom
  intended_uses: ''
  prohibited_uses: ''
  monitoring: unknown
  feedback: https://huggingface.co/01-ai/Yi-VL-34B/discussions
- type: model
  name: Kolors-IP-Adapter-Plus
  organization: Kwai-Kolors
  description: Kolors-IP-Adapter-Plus is an improved model based on Kolors-Basemodel. This model includes a stronger image feature extractor employing the Openai-CLIP-336 model as the image encoder, which preserves more details in reference images. It also utilizes diverse and high-quality training data inspired by data strategies of other works. The IP-Adapter-Plus weights and inference code are also provided.
  created_date: Unknown
  url: https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus
  model_card: https://huggingface.co/Kwai-Kolors/Kolors-IP-Adapter-Plus
  modality: "image; image" (This model likely uses an image as input and generates another image as output)
  analysis: The model was evaluated on a test set of over 200 reference images and text prompts. Image experts rated the generated images based on four criteria: visual appeal, text faithfulness, image faithfulness, and overall satisfaction. Kolors-IP-Adapter-Plus achieved the highest overall satisfaction score against other models in the evaluation.
  size: Unknown
  dependencies: [Kolors-Basemodel, Openai-CLIP-336, IP-Adapter]
  training_emissions: Unknown
  training_time: Unknown
  training_hardware: Unknown
  quality_control: The model was evaluated and rated by image experts for quality control, ensuring high image generation performance based on the criteria of visual appeal, text faithfulness, image faithfulness, and overall satisfaction.
  access: open
  license: Unknown
  intended_uses: The model is intended to be used for image enhancement and conversion tasks specifically focusing on preserving the details in the reference images.
  prohibited_uses: Unknown
  monitoring: Unknown
  feedback: Reporting of downstream problems with this model could be conducted by creating issues in the provided GitHub repository.
