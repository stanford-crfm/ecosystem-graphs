---
- type: model
  name: BioMedLM
  organization: Stanford
  description: ''
  created_date: 2022-12-15
  url: https://crfm.stanford.edu/2022/12/15/pubmedgpt.html
  model_card: ''
  modality: text; text
  analysis: ''
  size: 2.7B parameters (dense)
  dependencies: [The Pile]
  training_emissions: ''
  training_time: ''
  training_hardware: ''
  quality_control: ''
  access: open
  license: bigscience-bloom-rail-1.0
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: RoentGen
  organization: Stanford
  description: RoentGen is a generative medical imaging model that can create visually
    convincing X-ray images.
  created_date: 2022-11-23
  url: https://arxiv.org/pdf/2211.12737.pdf
  model_card: ''
  modality: text; image
  analysis: Evaluated on own framework that tests domain-specific tasks in medical
    field.
  size: 330M parameters (dense)
  dependencies: [Stable Diffusion, RoentGen radiology dataset]
  training_emissions: unknown
  training_time: 60k training steps per day
  training_hardware: 64 A100 GPUs
  quality_control: ''
  access: open
  license: ''
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: model
  name: CORGI
  organization: Stanford
  description: Model trained to generate language corrections for physical control
    tasks.
  created_date: 2023-06-12
  url: https://arxiv.org/pdf/2306.07012.pdf
  model_card: ''
  modality: human trajectories; text
  analysis: Evaluated on three physical control tasks, drawing, steering, and human
    body movement on various dynamics
  size: 124M parameters (dense)
  dependencies: [GPT-2, BABEL, text-davinci-003]
  training_emissions: ''
  training_time:
    explanation: The authors do not report the training time, but do report that
      they train for 200 epochs.
    value: unknown
  training_hardware: one NVIDIA A40 GPU
  quality_control: ''
  access: open
  license: MIT
  intended_uses: ''
  prohibited_uses: ''
  monitoring: ''
  feedback: ''
- type: dataset
  name: Alpaca dataset
  # General
  organization: Stanford
  description: >
    Alpaca dataset consistes of 52,000 instruction-following demonstrations generated
    in the style of the [Self-Instruct framework](https://github.com/yizhongw/self-instruct)
    using OpenAI's text-davinci-003 engine. This instruction data can be used to
    conduct instruction-tuning for language models and make the language model follow
    instruction better.
  created_date:
    value: 2023-03-13
    explanation: >
      The date the [[blog post]](https://crfm.stanford.edu/2023/03/13/alpaca.html)
      was released.
  url: https://crfm.stanford.edu/2023/03/13/alpaca.html
  datasheet: https://huggingface.co/datasets/tatsu-lab/alpaca
  modality: text (English)
  size: 52K instruction-following demonstrations
  sample: []
  analysis: ''
  # Construction
  dependencies: [text-davinci-003]
  license: CC BY-NC 4.0
  included: ''
  excluded: ''
  quality_control: ''
  # Downstream
  access:
    value: open
    explanation: The dataset can be downloaded from [[Hugging Face]](https://huggingface.co/datasets/tatsu-lab/alpaca).
      The code for generating data is available on the [[GitHub repository]](https://github.com/tatsu-lab/stanford_alpaca#data-generation-process).
  intended_uses: Alpaca is intended and licensed for research use only.
  prohibited_uses: ''
  monitoring: ''
  feedback: Feedback can be provided on [[GitHub Issues]](https://github.com/tatsu-lab/stanford_alpaca/issues).

- type: model
  name: Alpaca
  # General
  organization: Stanford
  description: >
    Alpaca-7B is an instruction-following model fine-tuned from the LLaMA 7B model
    on 52K instruction-following demonstrations.
  created_date:
    value: 2023-03-13
    explanation: >
      The date the [[blog post]](https://crfm.stanford.edu/2023/03/13/alpaca.html)
      was released.
  url: https://crfm.stanford.edu/2023/03/13/alpaca.html
  model_card: ''
  modality: text (English)
  size: 7B parameters (dense model)
  analysis: ''
  # Construction
  dependencies: [LLaMa, Alpaca dataset]
  training_emissions: unknown
  training_time: ''
  training_hardware: ''
  quality_control: ''
  # Downstream
  access:
    value: open
    explanation: The weight diff between Alpaca-7B and LLaMA-7B is located on the
      [[Hugging Face]](https://huggingface.co/tatsu-lab/alpaca-7b-wdiff). To recover
      the original Alpaca-7B weights, follow the steps given [[here]](https://github.com/tatsu-lab
      stanford_alpaca#recovering-alpaca-weights). Training and data generation code
      can be found on the [[GitHub repository]](https://github.com/tatsu-lab/stanford_alpaca).
      An [[online demo]](https://chat.lmsys.org/?model=alpaca-13b) is also available.
  license: CC BY NC 4.0 (model weights)
  intended_uses: Alpaca is intended and licensed for research use only.
  prohibited_uses: ''
  monitoring: ''
  feedback: Feedback can be provided on [[GitHub Issues]](https://github.com/tatsu-lab/stanford_alpaca/issues).
- type: model
  name: Merlin
  organization: Stanford University
  description: Merlin is a 3D Vision Language Model that uses both structured electronic health record (EHR) and unstructured radiology reports for supervision. It is used for abdominal CT interpretation. The model is trained on a high-quality clinical dataset of paired CT scans, EHR diagnosis codes, and radiology reports and evaluated on 6 task types and 752 individual tasks. The tasks include zero-shot findings classification, phenotype classification, zero-shot cross-modal retrieval, 5-year chronic disease prediction, radiology report generation, and 3D semantic segmentation.
  created_date: 2024 (exact date missing)
  url: https://arxiv.org/pdf/2406.06512
  model card: https://arxiv.org/pdf/2406.06512
  modality: 3D image; text
  analysis: Merlin was comprehensively evaluated on 6 task types and 752 individual tasks. This includes internal validation on a test set of 5,137 CTs, external validation on 7,000 clinical CTs, and on two public CT datasets (VerSe, TotalSegmentator).
  size: Unknown
  dependencies: ["CT scans dataset", "EHR diagnosis codes", "radiology reports"]
  training_emissions: Unknown
  training_time: Unknown
  training_hardware: Single GPU
  quality_control: The model was evaluated internally and externally on multiple clinical CTs and public CT datasets. It was compared with existing task-specific baselines to ensure it's performing favorably.
  access: limited (models, code, and dataset planned to be released after removal of all protected health information)
  license: Unknown
  intended_uses: The model is intended for use in abdominal CT interpretation. It helps in alleviating the burden of interpreting complex imaging studies, predicting chronic diseases, and extracting novel physiological insights from the images.
  prohibited_uses: The model should not be used for purposes that violate patient privacy and confidentiality.
  monitoring: Unknown
  feedback: Problems with the model can probably be reported directly to the corresponding author via email.
